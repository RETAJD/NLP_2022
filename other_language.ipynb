{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tw7y5difDKgC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Tuple, Dict\n",
        "import networkx as nx\n",
        "from networkx.algorithms import bipartite"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PUNKT 1**\n",
        "\n",
        "`Ranking        Wyraz(str).     F[procent] - czestotliwosc.      r x f(słupkami poziomymi)`"
      ],
      "metadata": {
        "id": "upt2Z9T4DoQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bledne_linie = 0 \n",
        "raw_text = []\n",
        "with open(\"Robinson.txt\", \"r\") as file:\n",
        "  for line in file:\n",
        "      if \"CHAPTER\" in line or len(line)<2:\n",
        "        bledne_linie+=1\n",
        "        if \"CHAPTER IV\" in line: \n",
        "          break\n",
        "      else: raw_text.append(line)\n",
        "# akapit 1\n",
        "raw_text[0]"
      ],
      "metadata": {
        "id": "nOyPdAtPDmrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zrobienie listy slow wszsytkich\n"
      ],
      "metadata": {
        "id": "f5RlLIU8GXor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaning and save to list\n",
        "same_słowa_lista = []\n",
        "for i in raw_text:\n",
        "  words = i.split(' ')\n",
        "  for j in range(len(words)):\n",
        "    if ',' in words[j]: words[j] = words[j].replace(',','')\n",
        "    if ';' in words[j]: words[j]= words[j].replace(';','')\n",
        "    if '(' in words[j]: words[j]= words[j].replace('(','')\n",
        "    if ')' in words[j]: words[j]= words[j].replace(')','')\n",
        "    if '»' in words[j]: words[j]= words[j].replace('»','')\n",
        "    if '«' in words[j]: words[j]= words[j].replace('«','')\n",
        "    if '.' in words[j]: words[j]= words[j].replace('.','')\n",
        "    if '\\n' in words[j]: words[j]= words[j].replace('\\n','')\n",
        "    if ':' in words[j]: words[j]= words[j].replace(':','')\n",
        "  same_słowa_lista.append(words)\n",
        "\n",
        "same_slowa = []\n",
        "\n",
        "for i in same_słowa_lista:\n",
        "  for j in i:\n",
        "    same_slowa.append(j)\n",
        "\n",
        "print(len(same_slowa))\n"
      ],
      "metadata": {
        "id": "-uTVmMJ7Gl-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counted: List[Tuple[str, int]] = [(unique_word, same_slowa.count(unique_word)) for unique_word in filter(lambda word: word, set(same_slowa))]"
      ],
      "metadata": {
        "id": "dacSmIi7KMcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counted.sort(key=lambda x: -x[1])"
      ],
      "metadata": {
        "id": "2WcgUgVcKTvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"rank|word|ratio|chart\")\n",
        "ytics: List[str] = []\n",
        "ratios: List[float] = []\n",
        "for idx, (word, occurences) in enumerate(counted, 1):\n",
        "  ratio: float = occurences/len(raw_text)*100\n",
        "  ytics.append(f'{idx} | {word} | {ratio} | ')\n",
        "  ratios.append(ratio*idx)\n",
        "\n",
        "plt.figure(figsize=(30, 650))\n",
        "plt.barh(ytics, ratios)\n",
        "# plt.xlim([0,5])\n",
        "plt.grid()\n",
        "plt.xlabel(\"r x f\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CEuOyOt4KWCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PUNKT 2**"
      ],
      "metadata": {
        "id": "k5ekD2tgKgcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words: List[str] = [word for word, _ in counted]\n",
        "\n",
        "\n",
        "# dla kazdego wyrazu z listy unique_words musimy znalezc ten wyraz w licie raw_text i do niego dopisac sasiadow\n",
        "nested_structure: Dict[str, Dict[str, int]] = {}\n",
        "plain_structure: Dict[str, int] = {unique_word: 0 for unique_word in unique_words}\n",
        "for idx, word in enumerate(same_slowa[:-2]):\n",
        "    for neigh_idx, neigh in enumerate(same_slowa[idx:idx+3]):\n",
        "        a, b = (word, neigh) if word<neigh else (neigh, word)\n",
        "        if not a in nested_structure:\n",
        "            nested_structure[a] = {}\n",
        "        if not b in nested_structure[a]:\n",
        "            nested_structure[a][b] = 0\n",
        "        nested_structure[a][b] += 1\n",
        "        plain_structure[a]+=1\n",
        "        plain_structure[b]+=1\n",
        "        "
      ],
      "metadata": {
        "id": "pk0uN_wDKbaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N: int = 20\n",
        "links_threshold: int = 10\n",
        "\n",
        "G = nx.Graph()\n",
        "G.add_nodes_from([node for node, links_count in plain_structure.items() if links_count > links_threshold], bipartite=0)\n",
        "G.add_nodes_from([node+' ' for node, links_count in plain_structure.items() if links_count > links_threshold], bipartite=1)\n",
        "G.add_edges_from((unique_word, neighbour+\" \") for unique_word, neighbours in nested_structure.items() for neighbour, count in neighbours.items() if count > N)\n",
        "\n",
        "\n",
        "is_bipartite: bool = bipartite.is_bipartite(G)"
      ],
      "metadata": {
        "id": "xXWiqiIGK9zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist([count for neighbours in nested_structure.values() for count in neighbours.values()], bins=500)\n",
        "plt.xlim([0, 20])"
      ],
      "metadata": {
        "id": "krtjnqjcLAT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(max(plain_structure, key = lambda key: plain_structure[key]))"
      ],
      "metadata": {
        "id": "7l7zVGxKLCAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(200,200)) #???\n",
        "nx.draw_networkx(G, pos = nx.drawing.layout.bipartite_layout(G, [word for word in unique_words]), width = 2, font_size=30)"
      ],
      "metadata": {
        "id": "eBC1zzQ3LEBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "zadanie 3"
      ],
      "metadata": {
        "id": "euE1zn3uLh1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pary_slow = []\n",
        "for i in same_słowa_lista :\n",
        "  for j in range(len(i)-1) :\n",
        "    pary_slow.append([i[j], i[j+1]])\n",
        "\n",
        "print(\"Ilość par słow wg jednego akapitu: \", len(pary_slow))\n",
        "\n",
        "# unikalna lista par\n",
        "unique_pary_slow = []\n",
        "for i in pary_slow:\n",
        "    if i not in unique_pary_slow:\n",
        "        unique_pary_slow.append(i)\n",
        "print(\"Ilość unikalnych par słow: \" , len(unique_pary_slow))\n",
        "\n",
        "\n",
        "counter = 0\n",
        "for i in unique_pary_slow:\n",
        "  for j in pary_slow:\n",
        "    if(i == j): counter += 1\n",
        "  i.append(counter)\n",
        "  counter = 0\n",
        "\n",
        "# posortowanie po ilosci wystapien\n",
        "unique_pary_slow.sort(key = lambda i: -i[2])\n",
        "\n",
        "# wyswietlenie wyniku\n",
        "for i in unique_pary_slow:\n",
        "  print(i[0],\"   \", i[1], \"  ilośc wystapień: \", i[2])"
      ],
      "metadata": {
        "id": "rtsZiZmyLfcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4IXruQOgLfUi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}